{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1NgKMRoPL2nVioZLUuGaj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9terry-student/pytorch/blob/main/9_Autoregressive_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "YRWVf41lWa6f"
      },
      "outputs": [],
      "source": [
        "# 라이브러리\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장->토큰화->토큰ID\n",
        "sentence=\"I went to the hospital\"\n",
        "tokens=sentence.lower().split()\n",
        "tokens.append(\"<EOS>\")\n",
        "print(\"tokens:\",tokens)\n",
        "\n",
        "vocab={w:i for i,w in enumerate(tokens)}\n",
        "print(\"vocab:\",vocab)\n",
        "\n",
        "inv_vocab={i:w for w,i in vocab.items()}\n",
        "\n",
        "token_ids=torch.tensor([[vocab[w] for w in tokens]])    # (B=1,S=5)\n",
        "print(\"token_ids:\",token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj_FQ6dYWbp8",
        "outputId": "e481df86-1fee-4ef1-a26a-8fa2e5300f03"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['i', 'went', 'to', 'the', 'hospital', '<EOS>']\n",
            "vocab: {'i': 0, 'went': 1, 'to': 2, 'the': 3, 'hospital': 4, '<EOS>': 5}\n",
            "token_ids: tensor([[0, 1, 2, 3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "B,S=token_ids.shape\n",
        "D=8\n",
        "\n",
        "embedding=nn.Embedding(len(vocab),D)\n",
        "x=embedding(token_ids)\n",
        "print(\"embedding output shape:\",x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__YnHdRgWbyL",
        "outputId": "520d74fa-a282-462d-ab55-603bf6fb47b9"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding output shape: torch.Size([1, 6, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding\n",
        "def positional_encoding(seq_len,embed_dim):\n",
        "  pe=torch.zeros(seq_len,embed_dim)\n",
        "  for pos in range(seq_len):\n",
        "    for i in range(0,embed_dim,2):\n",
        "      pe[pos,i]=math.sin(pos/(10000**(i/embed_dim)))\n",
        "      pe[pos,i+1]=math.cos(pos/(10000**(i/embed_dim)))\n",
        "  return pe\n",
        "\n",
        "pe=positional_encoding(S,D).unsqueeze(0)    # (1,S,D)\n",
        "x=x+pe    # 위치 정보 추가\n",
        "print(\"after positional encoding:\",x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zokBf2lxWb4a",
        "outputId": "da5329e4-87cc-4d81-e176-4a6cc0912afe"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after positional encoding: torch.Size([1, 6, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mask 생성 코드\n",
        "def causal_mask(seq_len):\n",
        "  return torch.tril(torch.ones(seq_len,seq_len))\n",
        "\n",
        "print(causal_mask(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU7lxOibWb-a",
        "outputId": "c407fd3b-21ee-4fd9-c505-2563dfe8a83c"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Masked Multi-Head Attention\n",
        "class MaskedMultiHeadAttention(nn.Module):\n",
        "  def __init__(self,embed_dim,num_heads):\n",
        "    super().__init__()\n",
        "    assert embed_dim%num_heads==0, \"D는 head 수로 나누어 떨어져야 함\"\n",
        "    self.num_heads=num_heads\n",
        "    self.head_dim=embed_dim//num_heads\n",
        "\n",
        "    # Q,K,V를 전체 D에서 한 번에 만들기\n",
        "    self.q=nn.Linear(embed_dim,embed_dim)\n",
        "    self.k=nn.Linear(embed_dim,embed_dim)\n",
        "    self.v=nn.Linear(embed_dim,embed_dim)\n",
        "\n",
        "    self.out=nn.Linear(embed_dim,embed_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    B,S,D=x.shape\n",
        "\n",
        "    # Q,K,V shape: (B,S,D)\n",
        "    Q=self.q(x)\n",
        "    K=self.k(x)\n",
        "    V=self.v(x)\n",
        "\n",
        "    # Multi-Head로 나누기: (B,head,S,head_dim)\n",
        "    Q=Q.view(B,S,self.num_heads,self.head_dim).transpose(1,2)\n",
        "    K=K.view(B,S,self.num_heads,self.head_dim).transpose(1,2)\n",
        "    V=V.view(B,S,self.num_heads,self.head_dim).transpose(1,2)\n",
        "\n",
        "    # Attention 계산\n",
        "    scores=Q@K.transpose(-2,-1)/(self.head_dim**0.5)\n",
        "\n",
        "    # Mask\n",
        "    mask=causal_mask(S).to(x.device)\n",
        "    scores=scores.masked_fill(mask==0,-1e9)\n",
        "\n",
        "    weights=F.softmax(scores,dim=-1)\n",
        "    out=weights@V   # (B,head,S,head_dim)\n",
        "\n",
        "    # 다시 합치기\n",
        "    out=out.transpose(1,2).contiguous().view(B,S,D)\n",
        "    out=self.out(out)\n",
        "    return out,weights"
      ],
      "metadata": {
        "id": "o_mbpXCUWcCn"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MiniEncoder Layer\n",
        "class MiniEncoder(nn.Module):\n",
        "  def __init__(self,embed_dim,num_heads):\n",
        "    super().__init__()\n",
        "    self.mha=MaskedMultiHeadAttention(embed_dim,num_heads)\n",
        "    self.norm1=nn.LayerNorm(embed_dim)\n",
        "    self.norm2=nn.LayerNorm(embed_dim)\n",
        "\n",
        "    self.ff=nn.Sequential(\n",
        "        nn.Linear(embed_dim,4*embed_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4*embed_dim,embed_dim)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    # Multi-Head+Residual+LayerNorm\n",
        "    attn_out,weights=self.mha(x)\n",
        "    x=self.norm1(x+attn_out)\n",
        "\n",
        "    # FeedForward+Residual+LayerNorm\n",
        "    ff_out=self.ff(x)\n",
        "    x=self.norm2(x+ff_out)\n",
        "\n",
        "    return x,weights"
      ],
      "metadata": {
        "id": "dV-kRDlkWcLU"
      },
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder Layer\n",
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self,embed_dim,num_heads):\n",
        "    super().__init__()\n",
        "    self.self_attn=MaskedMultiHeadAttention(embed_dim,num_heads)\n",
        "    self.norm1=nn.LayerNorm(embed_dim)\n",
        "    self.norm2=nn.LayerNorm(embed_dim)\n",
        "\n",
        "    self.ff=nn.Sequential(\n",
        "        nn.Linear(embed_dim,embed_dim*4),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(embed_dim*4,embed_dim)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    attn_out,attn_weights=self.self_attn(x)\n",
        "    x=self.norm1(x+attn_out)\n",
        "\n",
        "    ff_out=self.ff(x)\n",
        "    x=self.norm2(x+ff_out)\n",
        "\n",
        "    return x,attn_weights"
      ],
      "metadata": {
        "id": "jPcnFD7XWcpq"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Layer Encoder\n",
        "class EncoderStack(nn.Module):\n",
        "  def __init__(self,embed_dim,num_heads,num_layers):\n",
        "    super().__init__()\n",
        "    self.layers=nn.ModuleList([\n",
        "        MiniEncoder(embed_dim,num_heads)\n",
        "        for _ in range(num_layers)\n",
        "    ])\n",
        "\n",
        "  def forward(self,x):\n",
        "    all_attn=[]\n",
        "    for layer in self.layers:\n",
        "      x,attn=layer(x)\n",
        "      all_attn.append(attn)\n",
        "    return x,all_attn"
      ],
      "metadata": {
        "id": "ApJ2uJZCWp8s"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 입력 / 정답\n",
        "token_ids=torch.tensor([[vocab[w] for w in tokens]])    # (1,S)\n",
        "\n",
        "x_ids=token_ids[:,:-1]    # 입력\n",
        "y_ids=token_ids[:,1:]   # 정답\n",
        "\n",
        "print(\"x_ids:\",x_ids)\n",
        "print(\"y_ids:\",y_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEgbGqelXQLz",
        "outputId": "460ae66f-9bda-4226-8677-a00765e70b22"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_ids: tensor([[0, 1, 2, 3, 4]])\n",
            "y_ids: tensor([[1, 2, 3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder + 출력 헤드\n",
        "decoder=DecoderLayer(embed_dim=D,num_heads=2)\n",
        "lm_head=nn.Linear(D,len(vocab))"
      ],
      "metadata": {
        "id": "yUXr0okGYZaq"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss / Optimizer\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer=torch.optim.Adam(\n",
        "    list(embedding.parameters())+\n",
        "    list(decoder.parameters())+\n",
        "    list(lm_head.parameters()),\n",
        "    lr=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "jGWqUb16Yi3_"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for step in range(300):\n",
        "  x=embedding(x_ids)\n",
        "  x=x+positional_encoding(x.shape[1],D).unsqueeze(0)\n",
        "\n",
        "  dec_out,attn=decoder(x)\n",
        "  logits=lm_head(dec_out)\n",
        "\n",
        "  loss=loss_fn(\n",
        "      logits.view(-1,len(vocab)),\n",
        "      y_ids.view(-1)\n",
        "  )\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if step%50==0:\n",
        "    print(f\"step {step}, loss {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Leu8La-YyG_",
        "outputId": "83c3df90-cf56-47e1-bfb9-1b6b0c010db1"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0, loss 1.8205\n",
            "step 50, loss 0.0261\n",
            "step 100, loss 0.0076\n",
            "step 150, loss 0.0041\n",
            "step 200, loss 0.0026\n",
            "step 250, loss 0.0018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성 함수\n",
        "def generate(\n",
        "    start_tokens,   # list of token ids\n",
        "    max_len=10,\n",
        "    temperature=1.0,\n",
        "    eos_token=\"<EOS>\"\n",
        "):\n",
        "    generated=start_tokens[:]   # 복사\n",
        "    eos_id=vocab[eos_token]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "      x_ids=torch.tensor([generated])   # (1,T)\n",
        "\n",
        "      # embedding + PE\n",
        "      x=embedding(x_ids)\n",
        "      pe=positional_encoding(x.shape[1],x.shape[2]).unsqueeze(0)\n",
        "      x=x+pe\n",
        "\n",
        "      # decoder\n",
        "      dec_out,_=decoder(x)\n",
        "\n",
        "      # 마지막 토큰의 logits\n",
        "      logits=lm_head(dec_out[:,-1,:])   # (1,vocab)\n",
        "      logits=logits/temperature\n",
        "\n",
        "      # greedy decoding\n",
        "      next_id=logits.argmax(dim=-1).item()\n",
        "      generated.append(next_id)\n",
        "\n",
        "      if next_id==eos_id:\n",
        "        break\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "_jzpb4hhcOIw"
      },
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실제 생성해보기\n",
        "start=[vocab[\"i\"]]    # 시작 토큰: \"i\"\n",
        "\n",
        "generated_ids=generate(start_tokens=start,max_len=10)\n",
        "\n",
        "print(\"generated ids:\",generated_ids)\n",
        "print(\"generated text:\")\n",
        "for i in generated_ids:\n",
        "  print(inv_vocab[i],end=\" \")"
      ],
      "metadata": {
        "id": "I3s25bJ0h772",
        "outputId": "cc1bae97-37ea-492d-8cee-2647c29ce9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generated ids: [0, 1, 2, 3, 4, 5]\n",
            "generated text:\n",
            "i went to the hospital <EOS> "
          ]
        }
      ]
    }
  ]
}